@article{Durrant-Whyte2006,
abstract = {This tutorial provides an introduction to Simultaneous Localisation and Mapping (SLAM) and the extensive research on SLAM that has been undertaken over the past decade. SLAM is the process by which a mobile robot can build a map of an environment and at the same time use this map to compute it's own location. The past decade has seen rapid and exciting progress in solving the SLAM problem together with many compelling implementations of SLAM methods. Part I of this tutorial (this paper), describes the probabilistic form of the SLAM problem, essential solution methods and significant implementations. Part II of this tutorial will be concerned with recent advances in computational methods and new formulations of the SLAM problem for large scale and complex environments.},
archivePrefix = {arXiv},
arxivId = {there is not},
author = {Durrant-Whyte, Hugh and Bailey, Tim},
doi = {10.1109/MRA.2006.1638022},
eprint = {there is not},
file = {:data/OwnCloud/Studium/13. Semester ETH/SP2/Paper/2006{\_}Durrant-White{\_}Simultaneous Localisation and Mapping (SLAM)- Part I The Essential Algorithms.pdf:pdf},
isbn = {1070-9932},
issn = {10709932},
journal = {Robotics {\&} Automation Magazine},
keywords = {SLAM problem,mobile robots,simultaneous localization and mapping problem},
pages = {99--110},
pmid = {8460702},
title = {{Simultaneous localization and mapping (SLAM): part I The Essential Algorithms}},
volume = {2},
year = {2006}
}
@inproceedings{Forster2013,
abstract = {This paper presents a framework for collaborative localization and mapping with multiple Micro Aerial Vehicles (MAVs) in unknown environments. Each MAV estimates its motion individually using an onboard, monocular visual odometry algorithm. The system of MAVs acts as a distributed preprocessor that streams only features of selected keyframes and relative-pose estimates to a centralized ground station. The ground station creates an individual map for each MAV and merges them together whenever it detects overlaps. This allows the MAVs to express their position in a common, global coordinate frame. The key to real-time performance is the design of data-structures and processes that allow multiple threads to concurrently read and modify the same map. The presented framework is tested in both indoor and outdoor environments with up to three MAVs. To the best of our knowledge, this is the first work on real-time collaborative monocular SLAM, which has also been applied to MAVs.},
author = {Forster, Christian and Lynen, Simon and Kneip, Laurent and Scaramuzza, Davide},
booktitle = {IEEE International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2013.6696923},
file = {:data/SP2/papers/IROS13{\_}Forster{\_}CSFM.pdf:pdf},
isbn = {9781467363587},
issn = {21530858},
pages = {3963--3970},
title = {{Collaborative monocular SLAM with multiple Micro Aerial Vehicles}},
year = {2013}
}
@article{Galvez-Lopez2012,
abstract = {We propose a novel method for visual place recognition using bag of words obtained from accelerated segment test (FAST)+BRIEF features. For the first time, we build a vocabulary tree that discretizes a binary descriptor space and use the tree to speed up correspondences for geometrical verification. We present competitive results with no false positives in very different datasets, using exactly the same vocabulary and settings. The whole technique, including feature extraction, requires 22 ms/frame in a sequence with 26 300 images that is one order of magnitude faster than previous approaches.},
author = {G{\'{a}}lvez-L{\'{o}}pez, Dorian and Tard{\'{o}}s, Juan D.},
doi = {10.1109/TRO.2012.2197158},
file = {:data/OwnCloud/Studium/13. Semester ETH/SP2/Paper/2012{\_}Galvez-Lopez{\_}Bags  of  Binary  Words  for  Fast  Place  Recognition  in Image  Sequences.pdf:pdf},
isbn = {1552-3098},
issn = {15523098},
journal = {IEEE Transactions on Robotics},
keywords = {Bag of binary words,computer vision,place recognition,simultaneous localization and mapping (SLAM)},
number = {5},
pages = {1188--1197},
title = {{Bags of binary words for fast place recognition in image sequences}},
volume = {28},
year = {2012}
}
@article{Grisetti2010,
abstract = {Being able to build a map of the environment and to simultaneously localize within this map is an essential skill for mobile robots navigating in unknown environments in absence of external referencing systems such as GPS. This so-called simultaneous localization and mapping (SLAM) problem has been one of the most popular research topics in mobile robotics for the last two decades and efficient approaches for solving this task have been proposed. One intuitive way of formulating SLAM is to use a graph whose nodes correspond to the poses of the robot at different points in time and whose edges represent constraints between the poses. The latter are obtained from observations of the environment or from movement actions carried out by the robot. Once such a graph is constructed, the map can be computed by finding the spatial configuration of the nodes that is mostly consistent with the measurements modeled by the edges. In this paper, we provide an introductory description to the graph-based SLAM problem. Furthermore, we discuss a state-of-the-art solution that is based on least-squares error minimization and exploits the structure of the SLAM problems during optimization. The goal of this tutorial is to enable the reader to implement the proposed methods from scratch.},
author = {Grisetti, Giorgio and Kummerle, Rainer and Stachniss, Cyrill and Burgard, Wolfram},
doi = {10.1109/MITS.2010.939925},
file = {:data/OwnCloud/Studium/13. Semester ETH/SP2/Paper/2010{\_}Grisetti{\_}A Tutorial on Graph-Based SLAM.pdf:pdf},
isbn = {1939-1390 VO - 2},
issn = {1939-1390},
journal = {IEEE Intelligent Transportation Systems Magazine},
number = {4},
pages = {31--43},
title = {{A tutorial on graph-based SLAM}},
volume = {2},
year = {2010}
}
@article{Horn1987,
abstract = {Finding the relationship between two coordinate systems using pairs of measurements of the coordinates of a number of points in both systems is a classic photogrammetric task. It finds applications in stereophotogrammetry and in robotics. I present here a closed-form solution to the least-squares problem for three or more points. Currently various empirical, graphical, and numerical iterative methods are in use. Derivation of the solution is simplified by use of unit quaternions to represent rotation. I emphasize a symmetry property that a solution to this problem ought to possess. The best translational offset is the difference between the centroid of the coordinates in one system and the rotated and scaled centroid of the coordinates in the other system. The best scale is equal to the ratio of the root-mean-square deviations of the coordinates in the two systems from their respective centroids. These exact results are to be preferred to approximate methods based on measurements of a few selected points. The unit quaternion representing the best rotation is the eigenvector associated with the most positive eigenvalue of a symmetric 4 × 4 matrix. The elements of this matrix are combinations of sums of products of corresponding coordinates of the points.},
author = {Horn, Berthold K P},
doi = {10.1364/JOSAA.4.000629},
file = {:data/SP2/papers/josaa-4-4-629.pdf:pdf},
isbn = {1084-7529},
issn = {1084-7529},
journal = {Journal of the Optical Society of America A},
number = {4},
pages = {629},
title = {{Closed-form solution of absolute orientation using unit quaternions}},
volume = {4},
year = {1987}
}
@inproceedings{Kummerle2011,
abstract = {Many popular problems in robotics and computer vision including various types of simultaneous localization and mapping (SLAM) or bundle adjustment (BA) can be phrased as least squares optimization of an error function that can be represented by a graph. This paper describes the general structure of such problems and presents g2o, an open-source C++ framework for optimizing graph-based nonlinear error functions. Our system has been designed to be easily extensible to a wide range of problems and a new problem typically can be specified in a few lines of code. The current implementation provides solutions to several variants of SLAM and BA. We provide evaluations on a wide range of real-world and simulated datasets. The results demonstrate that while being general g2o offers a performance comparable to implementations of state of-the-art approaches for the specific problems.},
author = {K{\"{u}}mmerle, Rainer and Grisetti, Giorgio and Strasdat, Hauke and Konolige, Kurt and Burgard, Wolfram},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2011.5979949},
file = {:data/OwnCloud/Studium/13. Semester ETH/SP2/Paper/kuemmerle11icra.pdf:pdf},
isbn = {9781612843865},
issn = {10504729},
pages = {3607--3613},
pmid = {5979949},
title = {{G2o: A general framework for graph optimization}},
year = {2011}
}
@inproceedings{Lourakis2005,
abstract = {In order to obtain optimal 3D structure and viewing parameter estimates, bundle adjustment is often used as the last step of feature-based structure and motion estimation algorithms. Bundle adjustment involves the formulation of a large scale, yet sparse minimization problem, which is traditionally solved using a sparse variant of the Levenberg-Marquardt optimization algorithm that avoids storing and operating on zero entries. This paper argues that considerable computational benefits can be gained by substituting the sparse Levenberg-Marquardt algorithm in the implementation of bundle adjustment with a sparse variant of Powell's dog leg non-linear least squares technique. Detailed comparative experimental results provide strong evidence supporting this claim},
author = {Lourakis, M. I A and Argyros, Antonis A.},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.2005.128},
file = {:data/SP2/papers/01544898.pdf:pdf},
isbn = {076952334X},
issn = {1550-5499},
pages = {1526--1531},
title = {{Is Levenberg-Marquardt the most efficient optimization algorithm for implementing bundle adjustment?}},
volume = {II},
year = {2005}
}
@inproceedings{Mei2010,
abstract = {This paper proposes a new topo-metric representation of the world based on co-visibility that simplifies data association and improves the performance of appearance-based recognition. We introduce the concept of dynamic bagof-words, which is a novel form of query expansion based on finding cliques in the landmark co-visibility graph. The proposed approach avoids the - often arbitrary - discretisation of space from the robot's trajectory that is common to most image-based loop closure algorithms. Instead we show that reasoning on sets of co-visible landmarks leads to a simple model that out-performs pose-based or view-based approaches. Using real and simulated imagery, we demonstrate that dynamic bag-of-words query expansion can improve precision and recall for appearance-based localisation.},
author = {Mei, Christopher and Sibley, Gabe and Newman, Paul},
booktitle = {IEEE/RSJ 2010 International Conference on Intelligent Robots and Systems, IROS 2010 - Conference Proceedings},
doi = {10.1109/IROS.2010.5652266},
file = {:data/OwnCloud/Studium/13. Semester ETH/SP2/Paper/2010{\_}Mei{\_}Closing Loops Without Places.pdf:pdf},
isbn = {9781424466757},
issn = {2153-0858},
pages = {3738--3744},
title = {{Closing loops without places}},
year = {2010}
}
@article{Mur-Artal2015,
abstract = {The gold standard method for tridimensional reconstruction and camera localization from a set of images is well known to be Bundle Adjustment (BA). Although BA was regarded for years as a costly method restricted to the offline domain, several real time algorithms based on BA flourished in the last decade. However those algorithms were limited to perform SLAM in small scenes or only Visual Odometry. In this work we built on excellent algorithms of the last years to design from scratch a Monocular SLAM system that operates in real time, in small and large, indoor and outdoor environments, with the capability of wide baseline loop closing and relocalization, and including full automatic initialization. Our survival of the fittest approach to select the points and keyframes of the reconstruction generates a compact and trackable map that only grows if the scene content changes, enhancing lifelong operation. We present an exhaustive evaluation in 27 sequences from the most popular datasets achieving unprecedented performance with a typical localization accuracy from 0.2{\%} to 1{\%} of the trajectory dimension in scenes from a desk to several city blocks. We make public a ROS implementation.},
archivePrefix = {arXiv},
arxivId = {1502.00956},
author = {Mur-Artal, Raul and Montiel, J. M M and Tardos, Juan D.},
doi = {10.1109/TRO.2015.2463671},
eprint = {1502.00956},
file = {:data/OwnCloud/Studium/13. Semester ETH/SP2/Paper/2015{\_}Mur-Artal{\_}ORB-SLAM- a Versatile and Accurate Monocular SLAM System.pdf:pdf},
isbn = {1552-3098},
issn = {15523098},
journal = {IEEE Transactions on Robotics},
keywords = {Lifelong mapping,Simultaneous localization and mapping (SLAM),localization,monocular vision,recognition},
number = {5},
pages = {1147--1163},
title = {{ORB-SLAM: A Versatile and Accurate Monocular SLAM System}},
volume = {31},
year = {2015}
}
@article{Mur-Artal2016,
abstract = {We present ORB-SLAM2 a complete SLAM system for monocular, stereo and RGB-D cameras, including map reuse, loop closing and relocalization capabilities. The system works in real-time in standard CPUs in a wide variety of environments from small hand-held indoors sequences, to drones flying in industrial environments and cars driving around a city. Our backend based on Bundle Adjustment with monocular and stereo observations allows for accurate trajectory estimation with metric scale. Our system includes a lightweight localization mode that leverages visual odometry tracks for unmapped regions and matches to map points that allow for zero-drift localization. The evaluation in 29 popular public sequences shows that our method achieves state-of-the-art accuracy, being in most cases the most accurate SLAM solution. We publish the source code, not only for the benefit of the SLAM community, but with the aim of being an out-of-the-box SLAM solution for researchers in other fields.},
archivePrefix = {arXiv},
arxivId = {1610.06475},
author = {Mur-Artal, Raul and Tardos, Juan D.},
eprint = {1610.06475},
file = {:home/andreasziegler/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mur-Artal, Tardos - 2016 - ORB-SLAM2 an Open-Source SLAM System for Monocular, Stereo and RGB-D Cameras.pdf:pdf},
title = {{ORB-SLAM2: an Open-Source SLAM System for Monocular, Stereo and RGB-D Cameras}},
year = {2016}
}
@article{Strasdat2010,
abstract = {State of the art visual SLAM systems have recently been presented which are capable of accurate, large-scale and real-time performance, but most of these require stereo vision. Important application areas in robotics and beyond open up if similar performance can be demonstrated using monocular vision, since a single camera will always be cheaper, more compact and easier to calibrate than a multi-camera rig. With high quality estimation, a single camera moving through a static scene of course effectively provides its own stereo geometry via frames distributed over time. However, a classic issue with monocular visual SLAM is that due to the purely projective nature of a single camera, motion estimates and map structure can only be recovered up to scale. Without the known inter-camera distance of a stereo rig to serve as an anchor, the scale of locally constructed map portions and the corresponding motion estimates is therefore liable to drift over time. In this paper we describe a new near real-time visual SLAM system which adopts the continuous keyframe optimisation ap- proach of the best current stereo systems, but accounts for the additional challenges presented by monocular input. In particular, we present a new pose-graph optimisation technique which allows for the efficient correction of rotation, translation and scale drift at loop closures. Especially, we describe the Lie group of similarity transformations and its relation to the corresponding Lie algebra.We also present in detail the systems new image processing front-end which is able accurately to track hundreds of features per frame, and a filter-based approach for feature initialisation within keyframe-based SLAM. Our approach is proven via large-scale simulation and real-world experiments where a camera completes large looped trajectories.},
author = {Strasdat, Hauke and Montiel, J M M and Davison, Andrew J},
doi = {10.1.1.165.7975},
file = {:data/SP2/papers/2010{\_}Strasdat.pdf:pdf},
isbn = {978-0-262-51681-5},
issn = {2330765X},
journal = {Robotics: Science and Systems},
pages = {5},
title = {{Scale Drift-Aware Large Scale Monocular SLAM}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.165.7975{\&}rep=rep1{\&}type=pdf},
volume = {2},
year = {2010}
}
@article{Triggs2000,
abstract = {This paper is a survey of the theory and methods of photogrammetric bundle adjustment, aimed at potential implementors in the computer vision community. Bundle adjustment is the problem of refining a visual reconstruction to produce jointly optimal structure and viewing parameter estimates. Topics covered include: the choice of cost function and robustness; numerical optimization including sparse Newton methods, linearly convergent approximations, updating and recursive methods; gauge (datum) invariance; and quality control. The theory is developed for general robust cost functions rather than restricting attention to traditional nonlinear least squares.},
author = {Triggs, Bill and McLauchlan, Philip F. and Hartley, Richard I. and Fitzgibbon, Andrew W.},
doi = {10.1007/3-540-44480-7_21},
file = {:data/SP2/papers/chp{\%}3A10.1007{\%}2F3-540-44480-7{\_}21.pdf:pdf},
isbn = {978-3-540-67973-8},
issn = {978-3-540-67973-8},
journal = {Vision Algorithms: Theory and Practice},
keywords = {bundle adjustment,gauge freedom,optimization,scene reconstruction,sparse ma-,trices},
pages = {153--177},
title = {{Bundle Adjustment — A Modern Synthesis Vision Algorithms: Theory and Practice}},
url = {http://www.springerlink.com/content/plvcrq5bx753a2tn},
volume = {1883},
year = {2000}
}
@article{Umeyama1991,
abstract = {In many applications of computer vision, the following problem is$\backslash$nencountered. Two point patterns (sets of points)$\backslash$n{\{}{\textless}e1{\textgreater}x{\textless}/e1{\textgreater}{\textless}sub{\textgreater}i{\textless}/sub{\textgreater}{\}} and {\{}{\textless}e1{\textgreater}x{\textless}/e1{\textgreater}{\textless}sub{\textgreater}i{\textless}/sub{\textgreater}{\}}; {\textless}e1{\textgreater}i{\textless}/e1{\textgreater}=1, 2,$\backslash$n. . ., {\textless}e1{\textgreater}n{\textless}/e1{\textgreater} are given in {\textless}e1{\textgreater}m{\textless}/e1{\textgreater}-dimensional space, and the$\backslash$nsimilarity transformation parameters (rotation, translation, and$\backslash$nscaling) that give the least mean squared error between these point$\backslash$npatterns are needed. Recently, K.S. Arun et al. (1987) and B.K.P. Horn$\backslash$net al. (1987) presented a solution of this problem. Their solution,$\backslash$nhowever, sometimes fails to give a correct rotation matrix and gives a$\backslash$nreflection instead when the data is severely corrupted. The proposed$\backslash$ntheorem is a strict solution of the problem, and it always gives the$\backslash$ncorrect transformation parameters even when the data is corrupted},
author = {Umeyama, Shinji},
doi = {10.1109/34.88573},
file = {:data/SP2/papers/paper{\_}Umeyama.pdf:pdf},
isbn = {0162-8828},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Absolute orientation problem,computer vision,least-squares,motion estimation,singular value decomposition},
number = {4},
pages = {376--380},
title = {{Least-Squares Estimation of Transformation Parameters Between Two Point Patterns}},
volume = {13},
year = {1991}
}
@book{Bishop2006,
abstract = {The dramatic growth in practical applications for machine learning over the last ten years has been accompanied by many important developments in the underlying algorithms and techniques. For example, Bayesian methods have grown from a specialist niche to become mainstream, while graphical models have emerged as a general framework for describing and applying probabilistic techniques. The practical applicability of Bayesian methods has been greatly enhanced by the development of a range of approximate inference algorithms such as variational Bayes and expectation propagation, while new models based on kernels have had a significant impact on both algorithms and applications. This completely new textbook reflects these recent developments while providing a comprehensive introduction to the fields of pattern recognition and machine learning. It is aimed at advanced undergraduates or first-year PhD students, as well as researchers and practitioners. No previous knowledge of pattern recognition or machine learning concepts is assumed. Familiarity with multivariate calculus and basic linear algebra is required, and some experience in the use of probabilities would be helpful though not essential as the book includes a self-contained introduction to basic probability theory. The book is suitable for courses on machine learning, statistics, computer science, signal processing, computer vision, data mining, and bioinformatics. Extensive support is provided for course instructors, including more than 400 exercises, graded according to difficulty. Example solutions for a subset of the exercises are available from the book web site, while solutions for the remainder can be obtained by instructors from the publisher. The book is supported by a great deal of additional material, and the reader is encouraged to visit the book web site for the latest information. A forthcoming companion volume will deal with practical aspects of pattern recognition and machine learning, and will include free software implementations of the key algorithms along with example data sets and demonstration programs. Christopher Bishop is Assistant Director at Microsoft Research Cambridge, and also holds a Chair in Computer Science at the University of Edinburgh. He is a Fellow of Darwin College Cambridge, and was recently elected Fellow of the Royal Academy of Engineering. The author's previous textbook "Neural Networks for Pattern Recognition" has been widely adopted.},
archivePrefix = {arXiv},
arxivId = {0-387-31073-8},
author = {Bishop, Christopher M},
booktitle = {Pattern Recognition},
doi = {10.1117/1.2819119},
eprint = {0-387-31073-8},
isbn = {9780387310732},
issn = {10179909},
number = {4},
pages = {738},
pmid = {8943268},
title = {{Pattern Recognition and Machine Learning}},
url = {http://www.library.wisc.edu/selectedtocs/bg0137.pdf},
volume = {4},
year = {2006}
}
@book{Dahmen2013,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21{\%} with default Glide SP settings to 58{\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Dahmen, W. and Reusken, A.},
booktitle = {Journal of Chemical Information and Modeling},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {icle},
number = {9},
pages = {1689--1699},
pmid = {25246403},
title = {{Numerik f{\"{u}}r Ingenieure und Naturwissenschaftler}},
volume = {53},
year = {2013}
}
@article{powell1970hybrid,
  title={A hybrid method for nonlinear equations},
  author={Powell, Michael JD},
  journal={Numerical methods for nonlinear algebraic equations},
  volume={7},
  pages={87--114},
  year={1970}
}
@article{Triggs2000,
abstract = {This paper is a survey of the theory and methods of photogrammetric bundle adjustment, aimed at potential implementors in the computer vision community. Bundle adjustment is the problem of refining a visual reconstruction to produce jointly optimal structure and viewing parameter estimates. Topics covered include: the choice of cost function and robustness; numerical optimization including sparse Newton methods, linearly convergent approximations, updating and recursive methods; gauge (datum) invariance; and quality control. The theory is developed for general robust cost functions rather than restricting attention to traditional nonlinear least squares.},
author = {Triggs, Bill and McLauchlan, Philip F. and Hartley, Richard I. and Fitzgibbon, Andrew W.},
doi = {10.1007/3-540-44480-7_21},
file = {:data/SP2/papers/chp{\%}3A10.1007{\%}2F3-540-44480-7{\_}21.pdf:pdf},
isbn = {978-3-540-67973-8},
issn = {978-3-540-67973-8},
journal = {Vision Algorithms: Theory and Practice},
keywords = {bundle adjustment,gauge freedom,optimization,scene reconstruction,sparse ma-,trices},
pages = {153--177},
title = {{Bundle Adjustment — A Modern Synthesis Vision Algorithms: Theory and Practice}},
url = {http://www.springerlink.com/content/plvcrq5bx753a2tn},
volume = {1883},
year = {2000}
}
@misc{ wiki:landmark,
  author = {{Simultaneous localization and mapping}},
  title = "Simultaneous localization and mapping --- {W}ikipedia{,} The Free Encyclopedia",
  year = "2017",
  url = "https://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping",
  note = "[Online; accessed 22-Januar-2017]"
}
